{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fichier enregistré sous : data/grippe_data_vaccin.csv\n",
      "❌ Une erreur s'est produite : No module named 'psycopg2'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "#from airflow.models import Variable\n",
    "\n",
    "def fetch_grippe_data(type: str = \"vaccin\", save: bool = False):\n",
    "    if type == \"vaccin\":\n",
    "        url = \"https://www.data.gouv.fr/fr/datasets/r/848e3e48-4971-4dc5-97c7-d856cdfde2f6\"\n",
    "    elif type == \"cas\":  \n",
    "        url = \"https://www.sentiweb.fr/api/v1/datasets/rest/incidence?indicator=3&geo=PAY&span=all\"\n",
    "    else:\n",
    "        print(\"Type inconnu\")\n",
    "        return None\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Évite certains blocages\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = StringIO(response.text)\n",
    "            df = pd.read_csv(data, sep=\",\")  # Change `sep=\";\"` si nécessaire\n",
    "\n",
    "            # Enregistrer le fichier si l'option est activée\n",
    "            if save:\n",
    "                save_path = \"data\"  # Dossier où enregistrer le fichier\n",
    "                os.makedirs(save_path, exist_ok=True)  # Crée le dossier s'il n'existe pas\n",
    "                filename = os.path.join(save_path, f\"grippe_data_{type}.csv\")  \n",
    "                df.to_csv(filename, index=False, encoding=\"utf-8\")\n",
    "                print(f\"✅ Fichier enregistré sous : {filename}\")\n",
    "\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(\"❌ Erreur lors de la lecture du CSV :\", e)\n",
    "            return None\n",
    "    else:\n",
    "        print(\"❌ Erreur HTTP:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "# Exemple d'utilisation : récupérer et enregistrer le fichier dans `data/`\n",
    "df = fetch_grippe_data(\"vaccin\", save=True)\n",
    "\n",
    "def enregistrer_dans_postgres():\n",
    "    try:\n",
    "        # Récupération des informations de connexion depuis Airflow Variables\n",
    "       \n",
    "\n",
    "        host=\"ep-dark-cell-a27yju5c.eu-central-1.pg.koyeb.app\",  # Exemple: \"postgres.koyeb.app\"\n",
    "        db=\"grippe_vaccins\",  # Exemple: \"spotify_data\"\n",
    "        login=\"koyeb-adm\",     # Exemple: \"postgres\"\n",
    "        port=5432\n",
    "        password=\"npg_KfdxUp3W5bXI\"     # Exemple: \"password\"\n",
    "\n",
    "        # Création de la chaîne de connexion avec SQLAlchemy\n",
    "        connection_string = f\"postgresql://{login}:{password}@{host}:{port}/{db}\"\n",
    "        engine = create_engine(connection_string)\n",
    "\n",
    "        # Définir le chemin du fichier CSV dans le dossier 'data'\n",
    "        csv_path = os.path.join('data', 'grippe_data_vaccin.csv')  # ou le fichier spécifique que tu souhaites\n",
    "\n",
    "        # Charger le fichier CSV dans un DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Optionnel: Si tu veux vérifier les premières lignes du DataFrame\n",
    "        print(df.head())  # Affiche les 5 premières lignes pour débogage\n",
    "\n",
    "        # Enregistrer le DataFrame dans la table PostgreSQL\n",
    "        df.to_sql(\n",
    "            name='grippe_vaccins',   # Nom de la table dans la base PostgreSQL\n",
    "            con=engine,                # Connexion à la base via SQLAlchemy\n",
    "            if_exists='append',        # Ajouter les nouvelles lignes sans supprimer les anciennes\n",
    "            index=False                # Ne pas ajouter l'index comme colonne\n",
    "        )\n",
    "\n",
    "        print(\"✅ Les données ont été enregistrées dans la base PostgreSQL avec succès.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Une erreur s'est produite : {e}\")\n",
    "enregistrer_dans_postgres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringIO\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msqlalchemy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_engine\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    " #host = Variable.get(\"koyeb_postgres_host\")\n",
    "       # login = Variable.get(\"koyeb_postgres_user\")\n",
    "      #  password = Variable.get(\"koyeb_postgres_password\")\n",
    "      #  port = Variable.get(\"koyeb_postgres_port\")\n",
    "     #   db = Variable.get(\"koyeb_postgres_db\")\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "def enregistrer_dans_postgres():\n",
    "    try:\n",
    "        # Récupération des informations de connexion depuis Airflow Variables\n",
    "\n",
    "        host=\"ep-dark-cell-a27yju5c.eu-central-1.pg.koyeb.app\"  # Exemple: \"postgres.koyeb.app\"\n",
    "        db=\"grippe_vaccins\"  # Exemple: \"spotify_data\"\n",
    "        login=\"koyeb-adm\"   # Exemple: \"postgres\"\n",
    "        port=5432\n",
    "        password=\"npg_KfdxUp3W5bXI\"     # Exemple: \"password\"\n",
    "\n",
    "        # Création de la chaîne de connexion avec SQLAlchemy\n",
    "        connection_string = f\"postgresql://{login}:{password}@{host}:{port}/{db}\"\n",
    "        engine = create_engine(connection_string)\n",
    "\n",
    "        # Définir le chemin du fichier CSV dans le dossier 'data'\n",
    "        csv_path = os.path.join('data', 'grippe_data_vaccin.csv')  # ou le fichier spécifique que tu souhaites\n",
    "\n",
    "        # Charger le fichier CSV dans un DataFrame\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Optionnel: Si tu veux vérifier les premières lignes du DataFrame\n",
    "        print(df.head())  # Affiche les 5 premières lignes pour débogage\n",
    "\n",
    "        # Enregistrer le DataFrame dans la table PostgreSQL\n",
    "        df.to_sql(\n",
    "            name='grippe_vaccins',   # Nom de la table dans la base PostgreSQL\n",
    "            con=engine,                # Connexion à la base via SQLAlchemy\n",
    "            if_exists='append',        # Ajouter les nouvelles lignes sans supprimer les anciennes\n",
    "            index=False                # Ne pas ajouter l'index comme colonne\n",
    "        )\n",
    "\n",
    "        print(\"✅ Les données ont été enregistrées dans la base PostgreSQL avec succès.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Une erreur s'est produite : {e}\")\n",
    "enregistrer_dans_postgres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2-binary\n",
      "  Using cached psycopg2-binary-2.9.10.tar.gz (385 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[21 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing psycopg2_binary.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to psycopg2_binary.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to psycopg2_binary.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Error: pg_config executable not found.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m pg_config is required to build psycopg2 from source.  Please add the directory\n",
      "  \u001b[31m   \u001b[0m containing pg_config to the $PATH or specify the full executable path with the\n",
      "  \u001b[31m   \u001b[0m option:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m     python setup.py build_ext --pg-config /path/to/pg_config build ...\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m or with the pg_config option in 'setup.cfg'.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If you prefer to avoid building psycopg2 from source, please install the PyPI\n",
      "  \u001b[31m   \u001b[0m 'psycopg2-binary' package instead.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m For further information please check the 'doc/src/install.rst' file (also at\n",
      "  \u001b[31m   \u001b[0m <https://www.psycopg.org/docs/install.html>).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
